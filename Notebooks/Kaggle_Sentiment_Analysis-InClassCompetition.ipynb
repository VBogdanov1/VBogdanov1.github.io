{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis of product reviews for Kaggle Competition  (https://www.kaggle.com/c/product-reviews-sentiment-analysis/)  | Vladimir Bogdanov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are only 100 examples provided as a test sample - a situation when there is almost no marked data  (in general very frequent in the industrial analysis of the data). So I'm going to form the sufficient training set myself via web-parsing of existing reviews databases.\n",
    "\n",
    "## After forming a training set, I'll try to use VotingClassifier (hard/soft), manually compare different classifiers, fine-tune their parameters via GridSearch and finally obtain the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Importing neccessary libraries and importing test data from Kaggle API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/VB/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VB/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/VB/.kaggle/kaggle.json'\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.3.4 / client 1.1.0)\n",
      "test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c product-reviews-sentiment-analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('test.csv', 'r') as f:\n",
    "    data = f.read()\n",
    "    data_array_test = pd.DataFrame([r.text for r in bs4.BeautifulSoup(data, 'lxml').find_all('review')])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### It's very difficult to use pandas.read_csv to read this file due to its complex structure. \n",
    "### data_test = pd.read_csv('test.csv', sep='\\</review>', encoding='utf-8', keep_default_na=False, squeeze=False, skipinitialspace=True, header = None, error_bad_lines=False, skip_blank_lines=True, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "print data_array_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0\n",
      "0   Ужасно слабый аккумулятор, это основной минус ...\n",
      "1   ценанадежность-неубиваемостьдолго держит батар...\n",
      "2   подробнее в комментариях\\nК сожалению, факт по...\n",
      "3   я любительница громкой музыки. Тише телефона у...\n",
      "4   Дата выпуска - 2011 г, емкость - 1430 mAh, тех...\n",
      "5   - Удобная Клавиатура и русская раскладка\\r- 2 ...\n",
      "6   Супер телефон!\\r1.QWERTY!!! Это самый лучший е...\n",
      "7   - толщина (помещается даже в брюки)\\r- аккумул...\n",
      "8   Аккумулятор ужасен! Хватает буквально на неско...\n",
      "9   1 удобный.клавеатура просто класс быстро пишеш...\n",
      "10  Метттлленнныййй-ммеееттлленный. Ну что это так...\n",
      "11  - Цена\\r- Камера\\r- Удобное переключение между...\n",
      "12  - Зарядка! Держит просто обалденно! Хватает на...\n",
      "13  Звук , 2 sim, удобная удобная qwerty клавиатур...\n",
      "14  1)2 симки!!!\\r2)Внешний дизайн телефона\\r3)Удо...\n",
      "15  2 сим.\\rДизайн (много цветов корпуса существуе...\n",
      "16  1.Кверти-клава\\r2.Две сим-карты\\r3.Громкий дин...\n",
      "17  Качество, глюки операционки.\\nПокупала как тол...\n",
      "18  Дизайн, 2 симки, камера\\nСломался мой филька V...\n",
      "19  цена\\rбатарея\\rвнешний вид\\rстандартный разъем...\n",
      "20  клавиатура, батарея, две сим карты, удобное ме...\n",
      "21  Тормозит, сборка ужасная, всё скрипит и люфтит...\n",
      "22  Встроенная память, не очень хорошая камера.\\nВ...\n",
      "23  1. отличный дизайн\\r2. батарею держит 4 дня\\r3...\n",
      "24  1 удобно держать в руке \\r2 не фонит(многие пи...\n",
      "25  плохой сенсор,игры тупят,программы плохо работ...\n",
      "26  Купила телефон на земену нокии 5130.\\rСначала ...\n",
      "27  Qwerty клавиатура.\\rОчень долго держит заряд -...\n",
      "28  - МИЗЕРНОЕ количество внутренней памяти (что о...\n",
      "29  - 2 sim\\r- qwerty / йцукен\\r- долгая батарея\\r...\n",
      "..                                                ...\n",
      "70  1) большой дисплей\\r2) приемлемая цена\\r3) бол...\n",
      "71  Китаец он и есть китаец , только этот более бр...\n",
      "72  - Плохие динамики. Мало того, что модель сама ...\n",
      "73  время работы от батареи очень мало, скудный вы...\n",
      "74  Слабый процессор и батарея. Как результат, мед...\n",
      "75  цена,стиль,качество,звук,клавиатура(ну для мен...\n",
      "76  - висит\\r- батарея через 1,5 года сдыхает, сей...\n",
      "77  После двух недель использования полезла резино...\n",
      "78  Windows shop ужасен, Несъёмная батарея, мини с...\n",
      "79  очень мало памяти - не хватает ни на что, стар...\n",
      "80  Самопроизвольно закрывает приложения и перезаг...\n",
      "81  Rачество сборки, крепкий, тугой нажим клавиш, ...\n",
      "82  оо, да. недостатки:D с чего бы начать.. тупой ...\n",
      "83  Память!!!!\\nДо этого пару месяцев назад оставл...\n",
      "84  1) Низкая цена\\r2) QWERTY клавиатура (когда 2 ...\n",
      "85  - WP8;\\r- Система занимает почти все место в 4...\n",
      "86  + Удобная qwerty клавиатура\\r+ Неплохой экран\\...\n",
      "87  Мощный аккумулятор, множество функций, есть да...\n",
      "88  Windows 8. Из за этой системы очень быстро зап...\n",
      "89  ПАМЯТЬ! ПАМЯТЬ! Очень мало памяти! Доходило до...\n",
      "90  1) Красивый дизайн телефона\\r2) Большой ассорт...\n",
      "91  Всегда хотела телефон с qwerty клавиатурой. Ку...\n",
      "92  КАТАСТРОФИЧЕСКИ не хватает внутренней памяти.\\...\n",
      "93  1. Цена.\\r2. Качество сборки.\\r3. QWERTY-клави...\n",
      "94  почти все, что есть в этом телефоне\\nЧестно го...\n",
      "95  Нет передней камеры, внутренняя память очень м...\n",
      "96  Звук при прослушивание музыки хороший,не глючи...\n",
      "97  Очень маленькая память забита вшитыми и соверш...\n",
      "98  Удобный корпус,стандартное меню нокиа,камера д...\n",
      "99  ПО, камера, отсутствие выбора приложение, нево...\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print data_array_test ### Проверим что файл правильно считался"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Using web parsing to form a training set of suficcient quality and size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_page(parser):\n",
    "    reviews = parser.findAll('div', attrs={'class':'review-item__content'})  \n",
    "    ratings = parser.findAll('span', attrs={'class':'review-item__rating-counter'})\n",
    "    texts = []\n",
    "    for review in reviews:\n",
    "        text_segment = review.findAll('span', attrs={'class':'js-more-text'})\n",
    "        text_sum = \"\"\n",
    "        for text in text_segment:\n",
    "            text_sum += text.text + \"\\n\"\n",
    "        texts.append(text_sum)\n",
    "    return texts, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all_texts = []\n",
    "#all_ratings = []\n",
    "#for i in range(1,555):\n",
    "#    url = 'https://torg.mail.ru/review/goods/mobilephones/?page='+str(i) ### Using MAIL.RU Phone Reviews base as a source. More than 10,000 reviews available there.\n",
    "#    parser = bs4.BeautifulSoup(requests.get(url).text, 'lxml')\n",
    "#    texts, ratings = parse_page(parser)\n",
    "#    all_texts.append(texts)\n",
    "#    for rating in ratings:\n",
    "#        all_ratings.append(int(rating.text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_texts = pd.DataFrame({'rate': all_ratings, 'text': np.array(all_texts).flatten()})\n",
    "#df_texts['Binary_Rate'] = df_texts['rate']//4 ### Subjective solution -  will consider marks {1,2,3} as a negative review overall,\n",
    "                                              ### and therefore {4,5} as a positive one.\n",
    "#df_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_texts.to_csv('mobile_reviews_mail.csv', sep=\"\\t\", encoding = 'utf-8', index=False) ##  Saving parsing results to csv file in order to reuse afterwards "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing was done earlier, so as for now I'm just loading the results from csv:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_texts = pd.read_csv('mobile_reviews_mail.csv', sep=\"\\t\")\n",
    "df_texts['Binary_Rate'] = df_texts['rate']//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7537\n",
       "0    2463\n",
       "Name: Binary_Rate, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texts.Binary_Rate.value_counts() ## let's look on classes balance after binarization of the review marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 3.  In order to use bag-of-words approach let's use CountVectorizer with default parameters as a first approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7881922837922838\n"
     ]
    }
   ],
   "source": [
    "c_vectorizer = CountVectorizer() \n",
    "data_messages_vectorized = c_vectorizer.fit_transform(df_texts['text'])\n",
    "estimator = LogisticRegression() \n",
    "scores = []\n",
    "likelihood = []\n",
    "### Let's check the baseline quality\n",
    "scores.append(cross_val_score(estimator, data_messages_vectorized, y = df_texts['Binary_Rate'], cv = 10, scoring = 'accuracy'))\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. To solve the classification problem, let's use the ensemble of classifiers with the VotingClassifier module from the scikit library. I'll compare their basic efficiency based on the accuracy metric and also estimate the effectiveness of the ensemble. Using default parameters for now.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78 (+/- 0.05) [Logistic Regression]\n",
      "Accuracy: 0.80 (+/- 0.05) [Naive Bayes]\n",
      "Accuracy: 0.78 (+/- 0.05) [SGD]\n",
      "Accuracy: 0.78 (+/- 0.05) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = MultinomialNB()\n",
    "clf3 = SGDClassifier(random_state=1, loss='log',n_iter=1000)\n",
    "eclf = VotingClassifier(estimators=[ ('lr', clf1), ('nb', clf2),('SGD', clf3)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Naive Bayes', 'SGD', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, data_messages_vectorized, df_texts['Binary_Rate'], cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Making a pipeline for process optimization and finding best parameters. Note: not using \"fit\" since firstly we need to find the best parameters via GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_pipeline = Pipeline(\n",
    "            [(\"vectorizer\", CountVectorizer()),\n",
    "            (\"classifier\", VotingClassifier(estimators=[ ('lr', clf1), ('nb', clf2),('SGD', clf3)], voting='hard'))]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### In order to find the best parameters for the classifiers we also need to work on vectorization process. \n",
    "### I will use bigrams and word analyzer in CountVectorizer to optimize the vectorization result\n",
    "c_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "data_messages_vectorized = c_vectorizer.fit_transform(df_texts['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
       "       1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'alpha': np.linspace(0.1,2,20)}\n",
    "grid_search_cv = GridSearchCV(MultinomialNB(), params, n_jobs=-1, verbose=1, cv=10)\n",
    "grid_search_cv.fit(data_messages_vectorized, df_texts['Binary_Rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.9999999999999999, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 10.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': array([0.1    , 0.21111, 0.32222, 0.43333, 0.54444, 0.65556, 0.76667,\n",
       "       0.87778, 0.98889, 1.1    ]), 'solver': ['liblinear', 'sag', 'saga'], 'class_weight': [None, 'balanced']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'C': np.linspace(0.1,1.1,10),'class_weight': [None,'balanced'], 'solver' : ['liblinear', 'sag', 'saga']}\n",
    "grid_search_cv = GridSearchCV(LogisticRegression(random_state=1, max_iter=5000), params, n_jobs=-1, verbose=1, cv=3)\n",
    "\n",
    "grid_search_cv.fit(data_messages_vectorized, df_texts['Binary_Rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.2111111111111111, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=5000,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=1,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=1000,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'penalty': ['l2', 'l1'], 'loss': ['hinge', 'log'], 'alpha': array([0.0001, 0.0012, 0.0023, 0.0034, 0.0045, 0.0056, 0.0067, 0.0078,\n",
       "       0.0089, 0.01  ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'loss': ['hinge', 'log'],'penalty' : ['l2', 'l1'], 'alpha': np.linspace(0.0001,0.01,10)}\n",
    "grid_search_cv = GridSearchCV(SGDClassifier(random_state=1, learning_rate='optimal', n_iter=1000), params, n_jobs=-1, verbose=1, cv=3)\n",
    "\n",
    "grid_search_cv.fit(data_messages_vectorized, df_texts['Binary_Rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.01, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=1000,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.  Now when the best parameters have been found, let's train the models and use them for the final results on the test sample. Note: VotingClassifier has two methods for weighting: hard and soft. Look through the documentation for further details (http://scikit-learn.org/stable/modules/ensemble.html).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81 (+/- 0.04) [Logistic Regression]\n",
      "Accuracy: 0.76 (+/- 0.01) [Naive Bayes]\n",
      "Accuracy: 0.79 (+/- 0.03) [SGD]\n",
      "Accuracy: 0.78 (+/- 0.02) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression(C=0.2, max_iter=5000, random_state=1, penalty = 'l2', solver = 'liblinear')\n",
    "clf2 = MultinomialNB(alpha=1)\n",
    "clf3 = SGDClassifier(random_state=1, loss = 'hinge', n_iter=1000, alpha = 0.01, learning_rate='optimal', penalty = 'l2')\n",
    "eclf = VotingClassifier(estimators=[ ('lr', clf1), ('nb', clf2),('SGD', clf3)], voting='soft')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Naive Bayes', 'SGD', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, data_messages_vectorized, df_texts['Binary_Rate'], cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a final pipeline,  gaining the predictions for test sample and forming a submission file for Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "     ...se=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pipeline = Pipeline(\n",
    "            [(\"vectorizer\", CountVectorizer(analyzer='word', ngram_range=(1, 2))),\n",
    "            (\"classifier\", VotingClassifier(estimators=[ ('lr', clf1), ('nb', clf2),('SGD', clf3)], voting='hard'))]\n",
    "        )\n",
    "\n",
    "clf_pipeline.fit(df_texts['text'], df_texts['Binary_Rate'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_pipeline.predict(data_array_test[0])\n",
    "y_pred = clf_pipeline.predict(data_array_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos', 'neg', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'pos', 'neg', 'pos', 'pos', 'pos', 'neg', 'pos', 'neg', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'neg', 'pos', 'pos', 'pos', 'neg', 'neg', 'neg', 'neg', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'neg', 'neg', 'pos', 'pos', 'pos', 'neg', 'neg', 'pos', 'pos', 'pos', 'neg', 'pos', 'pos', 'pos', 'neg', 'pos', 'neg', 'pos', 'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'pos', 'pos', 'pos', 'pos']\n"
     ]
    }
   ],
   "source": [
    "y_pred_str = []\n",
    "for i in y_pred:\n",
    "    if i==0: \n",
    "        y_pred_str.append('neg')\n",
    "    else: \n",
    "        y_pred_str.append('pos')\n",
    "print y_pred_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Submission_test = pd.DataFrame({'Id': np.arange(len(y_pred_str)), 'y': y_pred_str})\n",
    "Submission_test.to_csv('out_Ensemble_InclassCompetition_Final.csv', header=True, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### For this model (using VotingClassifier) result on Kaggle is below 0.85 overall. \n",
    "### It seems that ensembling isn't the best choice for this task. \n",
    "### Let's try the fine-tuned logistic regression separatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "     ...=1, penalty='l2', random_state=0,\n",
       "          solver='sag', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pipeline = Pipeline(\n",
    "            [(\"vectorizer\", CountVectorizer(analyzer='word', ngram_range=(1, 2))),\n",
    "            (\"classifier\", LogisticRegression(max_iter=5000, class_weight='balanced', random_state=0, solver='sag'))]\n",
    "        )\n",
    "\n",
    "clf_pipeline.fit(df_texts['text'], df_texts['Binary_Rate'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Submission_test = pd.DataFrame({'Id': np.arange(len(y_pred_str)), 'y': y_pred_str})\n",
    "Submission_test.to_csv('out_Ensemble_InclassCompetition_Final.csv', header=True, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### For this run we obtain a result of 0.94 on Kaggle. Mission done. \n",
    "### https://www.kaggle.com/c/product-reviews-sentiment-analysis/leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
